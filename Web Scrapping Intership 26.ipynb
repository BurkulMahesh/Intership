{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06dad076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bcc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.Write a python program to display all the header tags from wikipedia.org.\n",
    "def Get_Headers(url):\n",
    "    page=requests.get(url)\n",
    "    if page.status_code >=200 and  page.status_code < 300:\n",
    "        soup=BeautifulSoup(page.content)\n",
    "        Header=[]\n",
    "        for i in  soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "            Header.append(i.text.replace('\\n',\"\"))\n",
    "        return Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb335c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Get_Headers('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "def get_movie_list_imdb(url):    \n",
    "    #url='https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&ref_=adv_prv'\n",
    "    lst_movie=[]\n",
    "    while True:\n",
    "        #print(url)\n",
    "        #page=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&ref_=adv_prv')\n",
    "        page=requests.get(url)\n",
    "        if page.status_code >=200 and  page.status_code < 300:\n",
    "            md=BeautifulSoup(page.content)\n",
    "        else:\n",
    "            break\n",
    "        movies=md.find_all('div',class_=\"lister-item-content\")\n",
    "        #lst_movie=[]\n",
    "        df2=pd.DataFrame()\n",
    "        for movie in movies:\n",
    "            movie_rank=movie.find('span',class_=\"lister-item-index unbold text-primary\").text.replace('\\n','')\n",
    "            movie_name=movie.find('h3',class_=\"lister-item-header\").a.text.replace('\\n','')\n",
    "            movie_rating=movie.find('div',class_=\"inline-block ratings-imdb-rating\").text.replace('\\n','')\n",
    "            movie_yr=movie.find('span',class_=\"lister-item-year text-muted unbold\").text.replace('\\n','')\n",
    "            lst_movie.append({'movie_rank':movie_rank,'movie_name':movie_name,'movie_rating':movie_rating,'movie_yr':movie_yr})\n",
    "        df1=df2.append(lst_movie)\n",
    "        url_tag=md.find('div',class_=\"desc\").a.text\n",
    "        if 'Next' in url_tag:\n",
    "            url_link=md.find('div',class_=\"desc\").a['href']\n",
    "            url='https://www.imdb.com'+url_link\n",
    "            #print(url)\n",
    "        else:\n",
    "            break\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top100_movie_list_imdb('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&ref_=adv_prv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5326c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3.Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "def indian_movie(url):\n",
    "#page=requests.get('https://www.imdb.com/list/ls056092300/')\n",
    "    page=requests.get(url)\n",
    "    if page.status_code >=200 and  page.status_code < 300:\n",
    "        md=BeautifulSoup(page.content)\n",
    "        movies=md.find_all('div',class_=\"lister-item-content\")\n",
    "        lst_movie=[]\n",
    "        df2=pd.DataFrame()\n",
    "        for movie in movies:\n",
    "                    movie_rank=movie.find('span',class_=\"lister-item-index unbold text-primary\").text.replace('\\n','')\n",
    "                    movie_name=movie.find('h3',class_=\"lister-item-header\").a.text.replace('\\n','')\n",
    "                    movie_rating=movie.find('span',class_=\"ipl-rating-star__rating\").text.replace('\\n','')\n",
    "                    movie_yr=movie.find('span',class_=\"lister-item-year text-muted unbold\").text.replace('\\n','')\n",
    "                    lst_movie.append({'movie_rank':movie_rank,'movie_name':movie_name,'movie_rating':movie_rating,'movie_yr':movie_yr})\n",
    "        df1=df2.append(lst_movie)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_movie('https://www.imdb.com/list/ls056092300/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca856b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Write a python program to scrape product name, price and discounts from https://meesho.com/bags-ladies/pl/p7vbp .\n",
    "def meesho_products(url):\n",
    "    #page=requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "    page=requests.get(url)\n",
    "    if page.status_code >=200 and  page.status_code < 300:\n",
    "            meesho=BeautifulSoup(page.content)\n",
    "            prods=meesho.find_all('div',class_=\"Card__BaseCard-sc-b3n78k-0 cXRroa NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 eEBPAI NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 eEBPAI\")\n",
    "            meesho_list=[]\n",
    "            df1=pd.DataFrame()\n",
    "            for prod in prods:\n",
    "                prod_name=prod.find('p',class_=\"Text__StyledText-sc-oo0kvp-0 cPgaBh NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 hofZGw NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 hofZGw\").text\n",
    "                prod_price=prod.find('h5',class_=\"Text__StyledText-sc-oo0kvp-0 dLSsNI\").text.replace('₹','')\n",
    "                prod_discount=prod.find('p',class_=\"Text__StyledText-sc-oo0kvp-0 iDRzyZ NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 dppwvY NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 dppwvY\").text.replace(' discount on 1st order','')\n",
    "                final_disc=prod_discount.replace('₹','')\n",
    "                meesho_list.append({'prod_name':prod_name,'prod_price(₹)':prod_price,'prod_discount(₹)':final_disc})\n",
    "                df2=df1.append(meesho_list)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "meesho_products('https://meesho.com/bags-ladies/pl/p7vbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "if page.status_code >=200 and  page.status_code < 300:\n",
    "        icc=BeautifulSoup(page.content)\n",
    "        icc_teams=icc.find('table',class_=\"table\")\n",
    "        team_list=[]\n",
    "        df1=pd.DataFrame()\n",
    "        for team in icc_teams.find_all('tbody'):\n",
    "            rows=team.find_all('tr')\n",
    "            for row in rows:\n",
    "                icc_team_rank=int(row.find_all('td')[0].text)\n",
    "                #if icc_team_rank < 11:\n",
    "                icc_team_name=row.find('span',class_=\"u-hide-phablet\").text\n",
    "                icc_team_matches=row.find_all('td')[2].text\n",
    "                icc_team_points=row.find_all('td')[3].text\n",
    "                icc_team_ratings=row.find_all('td')[4].text.strip()\n",
    "                team_list.append({'icc_team_rank':icc_team_rank,'icc_team_name':icc_team_name,'icc_team_matches':icc_team_matches,'icc_team_points':icc_team_points,'icc_team_ratings':icc_team_ratings})\n",
    "                    #print(icc_team_rank,icc_team_name,icc_team_matches,icc_team_points,icc_team_ratings)\n",
    "                    #print(icc_team_ratings)\n",
    "                df2=df1.append(team_list)\n",
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.15 #b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "#c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "def icc_player(url):\n",
    "    page=requests.get(url)\n",
    "    if page.status_code >=200 and  page.status_code < 300:\n",
    "            icc=BeautifulSoup(page.content)\n",
    "            tables=icc.find_all('table')\n",
    "            table=icc.find('table',class_=\"table rankings-table\")\n",
    "            #print(table)\n",
    "            team_list=[]\n",
    "            df1=pd.DataFrame()\n",
    "            for row in table.find_all('tr'):\n",
    "                columns=row.find_all('td')\n",
    "                if (columns !=[]):\n",
    "                    c0=columns[0].text.replace('\\n','').split()\n",
    "                    c1=c0[0]\n",
    "                    c2=columns[1].text.replace('(0)','').strip()\n",
    "                    c3=columns[2].text.replace('(0)','').strip()\n",
    "                    c4=columns[3].text.replace('(0)','').strip()\n",
    "                    team_list.append({'Rank':c1,'Palyer':c2,'Team':c3,'Rating':c4})\n",
    "                    df2=df1.append(team_list)#print(c1,c2,c3,c4)\n",
    "    return df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4271c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_player('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef155b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_player('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ef376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q.16 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "if page.status_code >=200 and  page.status_code < 300:\n",
    "        icc=BeautifulSoup(page.content)\n",
    "        icc_teams=icc.find('table',class_=\"table\")\n",
    "        team_list=[]\n",
    "        df1=pd.DataFrame()\n",
    "        for team in icc_teams.find_all('tbody'):\n",
    "            rows=team.find_all('tr')\n",
    "            for row in rows:\n",
    "                icc_team_rank=int(row.find_all('td')[0].text)\n",
    "                #if icc_team_rank < 11:\n",
    "                icc_team_name=row.find('span',class_=\"u-hide-phablet\").text\n",
    "                icc_team_matches=row.find_all('td')[2].text\n",
    "                icc_team_points=row.find_all('td')[3].text\n",
    "                icc_team_ratings=row.find_all('td')[4].text.strip()\n",
    "                team_list.append({'icc_team_rank':icc_team_rank,'icc_team_name':icc_team_name,'icc_team_matches':icc_team_matches,'icc_team_points':icc_team_points,'icc_team_ratings':icc_team_ratings})\n",
    "                    #print(icc_team_rank,icc_team_name,icc_team_matches,icc_team_points,icc_team_ratings)\n",
    "                    #print(icc_team_ratings)\n",
    "                df2=df1.append(team_list)\n",
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.6 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "icc_player('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17201ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. #c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "icc_player('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b1df669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>November 19, 2019</td>\n",
       "      <td>In this video, we will be learning how to crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>Hey everyone. I wanted to give you an update o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>August 6, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>July 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>April 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Heading                Date  \\\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   November 19, 2019   \n",
       "1  Python Data Science Tutorial: Analyzing the 20...    October 17, 2019   \n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  September 21, 2019   \n",
       "3  Python Threading Tutorial: Run Code Concurrent...  September 12, 2019   \n",
       "4                                Update (2019-09-03)   September 3, 2019   \n",
       "5  Python Quick Tip: The Difference Between “==” ...      August 6, 2019   \n",
       "6  Python Tutorial: Calling External Commands Usi...       July 24, 2019   \n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         May 1, 2019   \n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         May 1, 2019   \n",
       "9  Clarifying the Issues with Mutable Default Arg...      April 24, 2019   \n",
       "\n",
       "                                             content  \n",
       "0  In this video, we will be learning how to crea...  \n",
       "1  In this Python Programming video, we will be l...  \n",
       "2  In this Python Programming video, we will be l...  \n",
       "3  In this Python Programming video, we will be l...  \n",
       "4  Hey everyone. I wanted to give you an update o...  \n",
       "5  In this Python Programming Tutorial, we will b...  \n",
       "6  In this Python Programming Tutorial, we will b...  \n",
       "7  In this Python Programming Tutorial, we will b...  \n",
       "8  In this Python Programming Tutorial, we will b...  \n",
       "9  In this Python Programming Tutorial, we will b...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content\n",
    "#and the code for the video from the link for the youtube video from the post.\n",
    "\n",
    "page=requests.get('https://coreyms.com/')\n",
    "if page.status_code >=200 and  page.status_code < 300:\n",
    "        coreym=BeautifulSoup(page.content)\n",
    "        #print(coreym)\n",
    "        heading=coreym.find_all('header',class_=\"entry-header\")\n",
    "        list1=[]\n",
    "        list2=[]\n",
    "        df1=pd.DataFrame()\n",
    "        for header in heading:\n",
    "            title=header.find('h2',class_='entry-title').text\n",
    "            time=header.find('time',class_='entry-time').text\n",
    "            #p1=header.find('p').text\n",
    "            #content=header.find('p').text\n",
    "            list1.append({'Heading':title,'Date':time})\n",
    "            df2=df1.append(list1)\n",
    "            #print(title,time)\n",
    "        content=coreym.find_all('div',class_=\"entry-content\")\n",
    "        for para in content:\n",
    "            p1=para.find('p').text\n",
    "            list2.append(p1)\n",
    "df2['content']=list2\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d78c2d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Raja...</td>\n",
       "      <td>Independent House,  6th Cross road,9th main ro...</td>\n",
       "      <td>1,320 sqft</td>\n",
       "      <td>₹63,045/Month</td>\n",
       "      <td>₹1.1 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Jaya...</td>\n",
       "      <td>Independent House, TMC Layout behind rajalaxmi...</td>\n",
       "      <td>2,800 sqft</td>\n",
       "      <td>₹2.21 Lacs/Month</td>\n",
       "      <td>₹3.85 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Blueberry Apartm...</td>\n",
       "      <td>Blueberry Apartment  13th E Main Rd, Channakes...</td>\n",
       "      <td>1,074 sqft</td>\n",
       "      <td>₹87,691/Month</td>\n",
       "      <td>₹1.53 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Mayitri Enclave ...</td>\n",
       "      <td>Mayitri Enclave  Mayitri Enclave, 39th C, 5T B...</td>\n",
       "      <td>1,450 sqft</td>\n",
       "      <td>₹44,705/Month</td>\n",
       "      <td>₹78 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Tarang Parkway A...</td>\n",
       "      <td>Tarang Parkway Apartment  2nd Main Rd, Shivana...</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹57,314/Month</td>\n",
       "      <td>₹1 Crore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  4+ BHK In Independent House  For Sale  In Raja...   \n",
       "1  4+ BHK In Independent House  For Sale  In Jaya...   \n",
       "2  2 BHK Apartment  For Sale  In Blueberry Apartm...   \n",
       "3  3 BHK Apartment  For Sale  In Mayitri Enclave ...   \n",
       "4  2 BHK Apartment  For Sale  In Tarang Parkway A...   \n",
       "\n",
       "                                            Location        Area  \\\n",
       "0  Independent House,  6th Cross road,9th main ro...  1,320 sqft   \n",
       "1  Independent House, TMC Layout behind rajalaxmi...  2,800 sqft   \n",
       "2  Blueberry Apartment  13th E Main Rd, Channakes...  1,074 sqft   \n",
       "3  Mayitri Enclave  Mayitri Enclave, 39th C, 5T B...  1,450 sqft   \n",
       "4  Tarang Parkway Apartment  2nd Main Rd, Shivana...  1,200 sqft   \n",
       "\n",
       "                EMI         Price  \n",
       "0     ₹63,045/Month   ₹1.1 Crores  \n",
       "1  ₹2.21 Lacs/Month  ₹3.85 Crores  \n",
       "2     ₹87,691/Month  ₹1.53 Crores  \n",
       "3     ₹44,705/Month      ₹78 Lacs  \n",
       "4     ₹57,314/Month      ₹1 Crore  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8) Write a python program to scrape house details from mentioned URL. \n",
    "#It should include house title, location, area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar.\n",
    "page=requests.get('https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIifSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIn0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Rajajinagar,&locality=Jayanagar,&locality=Indiranagar')\n",
    "if page.status_code >=200 and  page.status_code < 300:\n",
    "        nobroker=BeautifulSoup(page.content)\n",
    "        house_details=nobroker.find_all('div',class_=\"bg-white rounded-2 bg-clip-padding overflow-hidden my-1.2p mx-0.5p tp:border-b-0 tp:shadow-cardShadow tp:mt-0.5p tp:mx-0 tp:mb:1p hover:cursor-pointer nb__2_XSE\")\n",
    "        house_dtls=[]\n",
    "        df1=pd.DataFrame()\n",
    "        for house in house_details:\n",
    "            title=house.find('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\").text\n",
    "            location=house.find('div',class_='mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95').text\n",
    "            area=house.find('div',class_=\"font-semi-bold heading-6\").text\n",
    "            EMI=house.find('div',id='roomType').text\n",
    "            price=house.find('div',class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r-0\").div.text\n",
    "            house_dtls.append({'Title':title,'Location':location,'Area':area,'EMI':EMI,'Price': price})\n",
    "            df2=df1.append(house_dtls)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8caf8e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cousine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>2,000</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>1,400</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>2,000</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>3,000</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>1,700</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>2,400</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>1,800</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>1,900</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>1,800</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>2,000</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>800</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>1,500</td>\n",
       "      <td>North Indian, Mughlai, Desserts, Beverages</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>3,400</td>\n",
       "      <td>European, Italian, Asian, Continental</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name  \\\n",
       "0                    Castle Barbeque   \n",
       "1                    Jungle Jamboree   \n",
       "2                    Castle Barbeque   \n",
       "3                         Cafe Knosh   \n",
       "4               The Barbeque Company   \n",
       "5                        India Grill   \n",
       "6                     Delhi Barbeque   \n",
       "7   The Monarch - Bar Be Que Village   \n",
       "8                         World Cafe   \n",
       "9                  Indian Grill Room   \n",
       "10                   Mad 4 Bar B Que   \n",
       "11                       Barbeque 29   \n",
       "12                        Glasshouse   \n",
       "\n",
       "                                             Location  Price  \\\n",
       "0                      Connaught Place, Central Delhi  2,000   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi  1,400   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi  2,000   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...  3,000   \n",
       "4                  Gardens Galleria,Sector 38A, Noida  1,700   \n",
       "5                Hilton Garden Inn,Saket, South Delhi  2,400   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi  1,800   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad  1,900   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad  1,800   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon  2,000   \n",
       "10                               Sector 29, Faridabad    800   \n",
       "11                                     NIT, Faridabad  1,500   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...  3,400   \n",
       "\n",
       "                                        Cousine Rating  \\\n",
       "0                         North Indian, Chinese    3.5   \n",
       "1                  North Indian, Asian, Italian    3.9   \n",
       "2                         Chinese, North Indian    3.9   \n",
       "3                          Italian, Continental    4.3   \n",
       "4                         North Indian, Chinese      4   \n",
       "5                         North Indian, Italian    3.9   \n",
       "6                                  North Indian    3.7   \n",
       "7                         North Indian, Chinese    3.9   \n",
       "8            North Indian, Chinese, Continental    4.2   \n",
       "9                         North Indian, Mughlai    4.3   \n",
       "10                                 North Indian    3.6   \n",
       "11   North Indian, Mughlai, Desserts, Beverages    4.2   \n",
       "12        European, Italian, Asian, Continental      4   \n",
       "\n",
       "                                            Image_url  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "#i) Restaurant name\n",
    "#ii) Cuisine\n",
    "#iii) Location\n",
    "#iv) Ratings\n",
    "#v) Image URL\n",
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "if page.status_code >=200 and  page.status_code < 300:\n",
    "        dine=BeautifulSoup(page.content)\n",
    "        rest_details=dine.find_all('div',class_=\"restnt-main-wrap clearfix\")\n",
    "        rest_dtls=[]\n",
    "        df1=pd.DataFrame()\n",
    "        for rest in rest_details:\n",
    "            name=rest.find('a',class_=\"restnt-name ellipsis\").text\n",
    "            place=rest.find('div',class_=\"restnt-loc ellipsis\").text\n",
    "            data=rest.find('span',class_=\"double-line-ellipsis\").text.split('|')\n",
    "            price1=data[0].split()\n",
    "            price=price1[1]\n",
    "            cousin=data[-1]\n",
    "            rating=rest.find('div',class_=\"restnt-rating rating-4\").text\n",
    "            image=rest.find('img')['data-src']\n",
    "            rest_dtls.append({'Name':name,'Location':place,'Price':price,'Cousine':cousin,'Rating':rating,'Image_url':image})\n",
    "            #print(name,place,price,cousin,rating,image)\n",
    "            df2=df1.append(rest_dtls)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce8f3900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women's Red Busy Doin Nothing (DL) Plus Size B...</td>\n",
       "      <td>999</td>\n",
       "      <td>https://images.bewakoof.com/t320/busy-doin-not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women's Red Busy Doing Nothing  Plus Size Boyf...</td>\n",
       "      <td>999</td>\n",
       "      <td>https://images.bewakoof.com/t320/busy-doing-no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mickey Splash 2.O Half Sleeve T-shirt</td>\n",
       "      <td>799</td>\n",
       "      <td>https://images.bewakoof.com/t320/mickey-splash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mickey Splash 2.O Short Top T-shirt</td>\n",
       "      <td>999</td>\n",
       "      <td>https://images.bewakoof.com/t320/mickey-splash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eww Half Sleeve T-shirt</td>\n",
       "      <td>799</td>\n",
       "      <td>https://images.bewakoof.com/t320/eww-half-slee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eww Half Sleeve T-shirt</td>\n",
       "      <td>799</td>\n",
       "      <td>https://images.bewakoof.com/t320/eww-half-slee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Not Gender Roles Half Sleeve T-shirt</td>\n",
       "      <td>999</td>\n",
       "      <td>https://images.bewakoof.com/t320/not-gender-ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eww Boyfriend T-shirt</td>\n",
       "      <td>799</td>\n",
       "      <td>https://images.bewakoof.com/t320/eww-boyfriend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mickey Splash 2.O Half Sleeve T-shirt</td>\n",
       "      <td>799</td>\n",
       "      <td>https://images.bewakoof.com/t320/mickey-splash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eww Boyfriend T-shirt</td>\n",
       "      <td>799</td>\n",
       "      <td>https://images.bewakoof.com/t320/eww-boyfriend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product Price  \\\n",
       "0  Women's Red Busy Doin Nothing (DL) Plus Size B...   999   \n",
       "1  Women's Red Busy Doing Nothing  Plus Size Boyf...   999   \n",
       "2              Mickey Splash 2.O Half Sleeve T-shirt   799   \n",
       "3                Mickey Splash 2.O Short Top T-shirt   999   \n",
       "4                            Eww Half Sleeve T-shirt   799   \n",
       "5                            Eww Half Sleeve T-shirt   799   \n",
       "6               Not Gender Roles Half Sleeve T-shirt   999   \n",
       "7                              Eww Boyfriend T-shirt   799   \n",
       "8              Mickey Splash 2.O Half Sleeve T-shirt   799   \n",
       "9                              Eww Boyfriend T-shirt   799   \n",
       "\n",
       "                                           Image_URL  \n",
       "0  https://images.bewakoof.com/t320/busy-doin-not...  \n",
       "1  https://images.bewakoof.com/t320/busy-doing-no...  \n",
       "2  https://images.bewakoof.com/t320/mickey-splash...  \n",
       "3  https://images.bewakoof.com/t320/mickey-splash...  \n",
       "4  https://images.bewakoof.com/t320/eww-half-slee...  \n",
       "5  https://images.bewakoof.com/t320/eww-half-slee...  \n",
       "6  https://images.bewakoof.com/t320/not-gender-ro...  \n",
       "7  https://images.bewakoof.com/t320/eww-boyfriend...  \n",
       "8  https://images.bewakoof.com/t320/mickey-splash...  \n",
       "9  https://images.bewakoof.com/t320/eww-boyfriend...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10) Write a python program to scrape first 10 product details which include \n",
    "#product name , price , Image URL from https://www.bewakoof.com/women-tshirts?ga_q=tshirts .\n",
    "\n",
    "page=requests.get('https://www.bewakoof.com/women-t-shirts')\n",
    "if page.status_code >=200 and  page.status_code < 300:\n",
    "        bewakoof=BeautifulSoup(page.content)\n",
    "        Tshirts=bewakoof.find_all('div',class_=\"productCardBox\")\n",
    "        tshirt_dtls=[]\n",
    "        df1=pd.DataFrame()\n",
    "        count=1\n",
    "        for tshirt in Tshirts:\n",
    "            if count <=10:\n",
    "                pname=tshirt.find('h3').text\n",
    "                price=tshirt.find('span',class_=\"actualPriceText\").text\n",
    "                img=tshirt.find('img')['src']\n",
    "                tshirt_dtls.append({'Product':pname,'Price':price,'Image_URL':img})\n",
    "                df2=df1.append(tshirt_dtls)\n",
    "                #print(pname,count,price,img)\n",
    "            count=count+1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd2202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
